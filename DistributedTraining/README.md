
# SageMaker-Distributed-Training-Resource
---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2022.02.18**

Video:

(ê°•ë ¥ ì¶”ì²œ) Amazon SageMakerë¥¼ í†µí•œ ë”¥ëŸ¬ë‹ ë¶„ì‚° í•™ìŠµ ë° ë””ë²„ê±° í”„ë¡œíŒŒì¼ë§ í™œìš©í•˜ê¸° â€“ ìµœì˜ì¤€:: AWS Innovate 2021 (30 ë¶„)

* https://www.youtube.com/watch?v=lsTtoACAPj4

AWS re:Invent 2020: Fast training and near-linear scaling with DataParallel in Amazon SageMaker (30ë¶„)

* https://www.youtube.com/watch?v=EXmz5g8F2zU

AWS re:Invent 2020: Train billion-parameter models with model parallelism on Amazon SageMaker (30ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=vv52RsBM8o4

AWS on Air 2020: AWS Whatâ€™s Next ft. new libraries for distributed training on Amazon SageMaker (31ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=nz1EwsS5OiA

Scale up Training of Your ML Models with Distributed Training on Amazon SageMaker (Sep 2019)

* ê¸°ë³¸ì ì¸ ë¶„ì‚° í›ˆë ¨ì˜ ê°œë…ì„ ì†Œê°œ (15ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=CDg55-GkIm4&list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz&index=8



Blog:  ë°œí–‰ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ í•¨.

* Amazon SageMaker Simplifies Training Deep Learning Models With Billions of Parameters (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/amazon-sagemaker-simplifies-training-deep-learning-models-with-billions-of-parameters/
* New â€“ Data Parallelism Library in Amazon SageMaker Simplifies Training on Large Datasets (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/managed-data-parallelism-in-amazon-sagemaker-simplifies-training-on-large-datasets/
* New â€“ Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/
* How Latent Space used the Amazon SageMaker model parallelism library to push the frontiers of large-scale transformers (Mar 2020)
    * https://aws.amazon.com/ko/blogs/machine-learning/how-latent-space-used-the-amazon-sagemaker-model-parallelism-library-to-push-the-frontiers-of-large-scale-transformers/
* Distributed Training: Train BART/T5 for Summarization using ğŸ¤— Transformers and Amazon SageMaker (Apr 2021)
    * https://huggingface.co/blog/sagemaker-distributed-training-seq2seq
* Multi-GPU distributed deep learning training at scale with Ubuntu18 DLAMI, EFA on P3dn instances, and Amazon FSx for Lustre (Jun 2020)
    * https://aws.amazon.com/blogs/machine-learning/multi-gpu-distributed-deep-learning-training-at-scale-on-aws-with-ubuntu18-dlami-efa-on-p3dn-instances-and-amazon-fsx-for-lustre/
* (ê°•ì¶”) Hyundai reduces ML model training time for autonomous driving models using Amazon SageMaker (Jun 2021)
    * https://aws.amazon.com/ko/blogs/machine-learning/hyundai-reduces-training-time-for-autonomous-driving-models-using-amazon-sagemaker/
    * 

ê°œë°œì ê°€ì´ë“œ:

SageMaker Distributed Training

* https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/distributed-training.html



ì½”ë“œ

ì•„ë§ˆì¡´ ì„¸ì´ì§€ë©”ì´ì»¤ ì˜ˆì œ (ê³µì‹ ì˜ˆì œ)

* https://github.com/aws/amazon-sagemaker-examples/tree/master/training
* í•œê¸€ ë²ˆì—­
    * https://github.com/daekeun-ml/sagemaker-distributed-training


TensorFlow 

* SageMaker-Tensorflow-Step-by-Step ì›Œí¬ìƒµ 
    * ì„¸ì´ì§€ ë©”ì´ì»¤ TF Getting Started, Horovod, Data Distributed Parallelism í¬í•¨
    * https://github.com/gonsoomoon-ml/SageMaker-Tensorflow-Step-By-Step
* SageMaker Debugger, Profiler, and Data Distributed Parallelism
    *  https://github.com/daekeun-ml/sagemaker-distributed-training-tf2


PyTorch ì˜ˆì œ 

* SageMaker-PyTorch-Step-By-Step
    * ì„¸ì´ì§€ ë©”ì´ì»¤ Pytorch Getting Started, Horovod, Data Distributed Parallelism í¬í•¨
    * https://github.com/gonsoomoon-ml/SageMaker-PyTorch-Step-By-Step
* Oxford-IIT Pet Dataset ì‚¬ìš©í•˜ì—¬ Data Distributed Parallelism 
    * https://github.com/aws-samples/sagemaker-distributed-training-pytorch-kr



ì»¨í¼ëŸ°ìŠ¤ ë° ê¸°íƒ€

* Distributed Training with TensorFlow on AWS
    * https://github.com/shashankprasanna/distributed-training-workshop/blob/master/static/tf-world-distributed-training-workshop.pdf
* *SageMaker Prep Data (Image, Tabular, Text)*
    * https://github.com/aws/amazon-sagemaker-examples/tree/master/prep_data
* Accelerate computer vision training using GPU preprocessing with NVIDIA DALI on Amazon SageMaker

    * https://aws.amazon.com/ko/blogs/machine-learning/accelerate-computer-vision-training-using-gpu-preprocessing-with-nvidia-dali-on-amazon-sagemaker/

