
# SageMaker-Distributed-Training-Resource
---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2023.05.01**

# 0. FSx for Luster ì„¤ì¹˜ ê°€ì´ë“œ
- [aker Notebook ë° FSX for Luster ìƒì„± ê°€ì´ë“œ](https://github.com/gonsoomoon-ml/FSx-Luster-On-SageMaker/blob/main/0_setup_environment/1.VPC_SM_Notebook/README.md)

# 1. Video:

(ê°•ë ¥ ì¶”ì²œ) Amazon SageMakerë¥¼ í†µí•œ ë”¥ëŸ¬ë‹ ë¶„ì‚° í•™ìŠµ ë° ë””ë²„ê±° í”„ë¡œíŒŒì¼ë§ í™œìš©í•˜ê¸° â€“ ìµœì˜ì¤€:: AWS Innovate 2021 (30 ë¶„)

* https://www.youtube.com/watch?v=lsTtoACAPj4

AWS re:Invent 2020: Fast training and near-linear scaling with DataParallel in Amazon SageMaker (30ë¶„)

* https://www.youtube.com/watch?v=EXmz5g8F2zU

AWS re:Invent 2020: Train billion-parameter models with model parallelism on Amazon SageMaker (30ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=vv52RsBM8o4

AWS on Air 2020: AWS Whatâ€™s Next ft. new libraries for distributed training on Amazon SageMaker (31ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=nz1EwsS5OiA

Scale up Training of Your ML Models with Distributed Training on Amazon SageMaker (Sep 2019)

* ê¸°ë³¸ì ì¸ ë¶„ì‚° í›ˆë ¨ì˜ ê°œë…ì„ ì†Œê°œ (15ë¶„ ì†Œìš”)

* https://www.youtube.com/watch?v=CDg55-GkIm4&list=PLhr1KZpdzukcOr_6j_zmSrvYnLUtgqsZz&index=8



# 2. Blog:  ë°œí–‰ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ í•¨.

- (Jan 2023) ìŠ¤í… ë°”ì´ ìŠ¤í…ìœ¼ë¡œ BERT ë¥¼ ì„¸ì´ì§€ ë©”ì´ì»¤ë¡œ ìŠ¤í¬ë˜ì¹˜ë¶€í„° í›ˆë ¨í•˜ëŠ” ê°€ì´ë“œ ì…ë‹ˆë‹¤. 
    - [Â­Â­Â­Training BERT from Scratch on Your Custom Domain Data: A Step-by-Step Guide with Amazon SageMaker](https://medium.com/@shankar.arunp/training-bert-from-scratch-on-your-custom-domain-data-a-step-by-step-guide-with-amazon-25fcbee4316a)
- (Jan 2023) ì„¸ì´ì§€ ë©”ì´ì»¤ ê¸°ë°˜ì—ì„œ â€œìŠ¤í¬ë˜ì¹˜â€ ë¶€í„° GPT ë¥¼ í•™ìŠµí•˜ëŠ” ë¸”ë¡œê·¸ ì…ë‹ˆë‹¤. ê³ ê°ë“¤ì˜ í•´ë‹¹ ë„ë©”ì¸ì—ì„œ í•´ë³¼ ìˆ˜ ìˆê²Œ ê°€ì´ë“œ ì…ë‹ˆë‹¤. 
    - [Easily Build Your Own GPT from Scratch using AWS: A Comprehensive Guide for Domain Adaptation](https://medium.com/@shankar.arunp/easily-build-your-own-gpt-from-scratch-using-aws-51811b6355d3)

* Amazon SageMaker Simplifies Training Deep Learning Models With Billions of Parameters (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/amazon-sagemaker-simplifies-training-deep-learning-models-with-billions-of-parameters/
* New â€“ Data Parallelism Library in Amazon SageMaker Simplifies Training on Large Datasets (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/managed-data-parallelism-in-amazon-sagemaker-simplifies-training-on-large-datasets/
* New â€“ Profile Your Machine Learning Training Jobs With Amazon SageMaker Debugger (Dec 2020)
    * https://aws.amazon.com/ko/blogs/aws/profile-your-machine-learning-training-jobs-with-amazon-sagemaker-debugger/
* How Latent Space used the Amazon SageMaker model parallelism library to push the frontiers of large-scale transformers (Mar 2020)
    * https://aws.amazon.com/ko/blogs/machine-learning/how-latent-space-used-the-amazon-sagemaker-model-parallelism-library-to-push-the-frontiers-of-large-scale-transformers/
* Distributed Training: Train BART/T5 for Summarization using ğŸ¤— Transformers and Amazon SageMaker (Apr 2021)
    * https://huggingface.co/blog/sagemaker-distributed-training-seq2seq
* Multi-GPU distributed deep learning training at scale with Ubuntu18 DLAMI, EFA on P3dn instances, and Amazon FSx for Lustre (Jun 2020)
    * https://aws.amazon.com/blogs/machine-learning/multi-gpu-distributed-deep-learning-training-at-scale-on-aws-with-ubuntu18-dlami-efa-on-p3dn-instances-and-amazon-fsx-for-lustre/
* (ê°•ì¶”) Hyundai reduces ML model training time for autonomous driving models using Amazon SageMaker (Jun 2021)
    * https://aws.amazon.com/ko/blogs/machine-learning/hyundai-reduces-training-time-for-autonomous-driving-models-using-amazon-sagemaker/


* [ê°•ì¶”] Choose the best data source for your Amazon SageMaker training job (Feb 2022)
    - í›ˆë ¨ì„ í• ì‹œì— ì—¬ëŸ¬ê°€ì§€ ë°ì´í„° ì†ŒìŠ¤(s3, Fsx Luster, EFS ë“± ì„¤ëª…) íŠ¹ì¥ì  ë° ì„ íƒ ë°©ë²• ê°€ì´ë“œ
    - https://aws.amazon.com/blogs/machine-learning/choose-the-best-data-source-for-your-amazon-sagemaker-training-job/


- Transfer Learning with Amazon SageMaker and FSx for Lustre (Feb 2022)
    * ìƒ˜í”Œ ì½”ë“œëŠ” ì œê³µì„ ì•ˆí•˜ë‚˜ ì „ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µ í•˜ê³  ìˆìŒ.
    * https://medium.com/@sayons/transfer-learning-with-amazon-sagemaker-and-fsx-for-lustre-378fa8977cc1

# 3, ê°œë°œì ê°€ì´ë“œ:

SageMaker Distributed Training

* https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/distributed-training.html



# 4. ì½”ë“œ

ì•„ë§ˆì¡´ ì„¸ì´ì§€ë©”ì´ì»¤ ì˜ˆì œ (ê³µì‹ ì˜ˆì œ)

* https://github.com/aws/amazon-sagemaker-examples/tree/master/training
* í•œê¸€ ë²ˆì—­
    * https://github.com/daekeun-ml/sagemaker-distributed-training


TensorFlow 

* SageMaker-Tensorflow-Step-by-Step ì›Œí¬ìƒµ 
    * ì„¸ì´ì§€ ë©”ì´ì»¤ TF Getting Started, Horovod, Data Distributed Parallelism í¬í•¨
    * https://github.com/gonsoomoon-ml/SageMaker-Tensorflow-Step-By-Step
* SageMaker Debugger, Profiler, and Data Distributed Parallelism
    *  https://github.com/daekeun-ml/sagemaker-distributed-training-tf2


PyTorch ì˜ˆì œ 

* SageMaker-PyTorch-Step-By-Step
    * ì„¸ì´ì§€ ë©”ì´ì»¤ Pytorch Getting Started, Horovod, Data Distributed Parallelism í¬í•¨
    * https://github.com/gonsoomoon-ml/SageMaker-PyTorch-Step-By-Step
* Oxford-IIT Pet Dataset ì‚¬ìš©í•˜ì—¬ Data Distributed Parallelism 
    * https://github.com/aws-samples/sagemaker-distributed-training-pytorch-kr



# 4. ì»¨í¼ëŸ°ìŠ¤ ë° ê¸°íƒ€

* Distributed Training with TensorFlow on AWS
    * https://github.com/shashankprasanna/distributed-training-workshop/blob/master/static/tf-world-distributed-training-workshop.pdf
* *SageMaker Prep Data (Image, Tabular, Text)*
    * https://github.com/aws/amazon-sagemaker-examples/tree/master/prep_data
* Accelerate computer vision training using GPU preprocessing with NVIDIA DALI on Amazon SageMaker

    * https://aws.amazon.com/ko/blogs/machine-learning/accelerate-computer-vision-training-using-gpu-preprocessing-with-nvidia-dali-on-amazon-sagemaker/

